[{"content":"前言 上一篇文章我写了如何利用Docker搭建一个Hadoop-muti-node-cluster，从中我们得知Hadoop可以通过MapReduce机制实现一些计算任务，但是由于MapReduce任务需要跑很多次而且需要多次迭代，每次迭代计算结果都要存到HDFS中，而HDFS本质上就是硬盘，相当于把每次运算结果写入硬盘，而且还要考虑备份的问题，所以在MapReduce的传统计算中存储占用了绝大部分时间。而Spark不同，它是将中间计算结果存储在内存中并直接在内存中执行迭代计算，速度会更快（CPU直接访问内存速度远远快于访问磁盘），是现在非常流行的通用云计算引擎/框架。\n **官网描述：**Apache Spark 是用于大规模数据处理的统一分析引擎。它提供了 Java、Scala、Python 和 R 中的高级 API，以及支持通用执行图的优化引擎。它还支持一组丰富的更高级别的工具，包括SparkSQL用于SQL和结构化数据的处理，MLlib机器学习，GraphX用于图形处理，以及结构化流的增量计算和流处理。\n 1 - 搭建前注意事项 官网说明： Spark 应用程序作为集群上的独立进程集运行，由SparkContext 主程序（称为驱动程序）中的对象协调。\n具体来说，为了在集群上运行，SparkContext 可以连接到多种类型的集群管理器 （Spark 自己的独立集群管理器、Mesos、YARN 或 Kubernetes），它们在应用程序之间分配资源。连接后，Spark 会在集群中的节点上获取执行程序，这些进程为您的应用程序运行计算和存储数据。接下来，它将您的应用程序代码（由传递给 SparkContext 的 JAR 或 Python 文件定义）发送到执行程序。最后，SparkContext 将任务发送给执行程序以运行。\nSpark支持的集群管理器如下：\n Standalone– Spark 附带的简单集群管理器，可以轻松设置集群。 Apache Mesos – 一个通用的集群管理器，也可以运行 Hadoop MapReduce 和服务应用程序。（已弃用） Hadoop YARN – Hadoop 2 中的资源管理器。 Kubernetes – 一个开源系统，用于自动部署、扩展和管理容器化应用程序。   由以上说明在不同的集群模式（即选用不同的集群管理器）下，Spark有不同的部署方法，本文选用最简单的Standalone模式部署（其实Docker和Kubernetes搭建更好，最近没时间学，之后再写相关文章吧）\n 2 - 下载Spark\u0026amp;Scala  要安装 Spark Standalone 模式，您只需在集群的每个节点上放置一个编译版本的 Spark。\n  关于Spark的下载，一定要寻找对应Hadoop版本的Spark，否则可能会出现奇奇怪怪的问题。  Spark下载网址在这里：https://spark.apache.org/downloads.html   按照Spark下载网站上的说明下载对应的Scala版本（比如下面这个版本官网的说明就是建议下载Scala2.12版本）  Scala下载网址在这里：https://www.scala-lang.org/download/     关于二者的下载，如果看过我上篇文章的读者，应该已经发现在上篇文的Dockerfile中我已经下载了相应版本的Spark和Scala\n 3 - 配置环境变量 设置一下Spark必须用到的环境变量：（将下面这些环境变量配置的键值对写入~/.bashrc）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #SCALA Variables export PATH=${JAVA_HOME}/bin:${PATH} export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar export SCALA_HOME=/usr/local/scala export PATH=$PATH:$SCALA_HOME/bin export PATH=$PATH:$SCALA_HOME/sbin #SCALA Variables #SPARK Variables export SPARK_HOME=/usr/local/spark export PATH=$PATH:$SPARK_HOME/bin export SPARK_DIST_CLASSPATH=/usr/local/hadoop/bin/hadoop export PYTHONPATH=$SPARK_HOME/python/:$SPARK_HOME/python/lib/py4j-0.10.6-src.zip:$PYTHONPATH export PATH=$PATH:$SPARK_HOME/sbin #SPARK Variables   更新bash配置：\n1  source ~/.bashrc   4 - 配置Spark配置文件（conf目录） 1 - spark-env.sh文件   将下面这些配置写入$SPARK_HOME/conf目录下的spark-env.sh配置文件中（其中SPARK_MASTER_HOST出换成你master的ip地址，或者直接写master应该也可以）\n  注意，当Spark安装时，conf/spark-env.sh默认是不存在的。你可以复制conf/spark-env.sh.template创建它（cp spark-env.sh.template spark-env.sh），其他配置文件也同理。\n  1 2 3 4 5 6 7 8 9 10  export SPARK_DIST_CLASSPATH=/usr/local/hadoop/bin/hadoop export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export SCALA_HOME=/usr/local/scala export HADOOP_HOME=/usr/local/hadoop export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop export SPARK_MASTER_HOST=172.18.0.2 export SPARK_HOME=/usr/local/spark export SPARK_WORKER_CORES=1 export SPARK_WORKER_MEMORY=512m export SPARK_WORKER_INSTANCES=2   2 - Workers # # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # A Spark Worker will be started on each of the machines listed below. # 在这里写上包括master节点在内的所有工作节点 master slave1 slave2 3 - log4j.properties  打印Spark运行日志，方便后期排错和检查运行情况  # # Licensed to the Apache Software Foundation (ASF) under one or more # contributor license agreements. See the NOTICE file distributed with # this work for additional information regarding copyright ownership. # The ASF licenses this file to You under the Apache License, Version 2.0 # (the \u0026quot;License\u0026quot;); you may not use this file except in compliance with # the License. You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \u0026quot;AS IS\u0026quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Set everything to be logged to the console log4j.rootCategory=WARN, console log4j.appender.console=org.apache.log4j.ConsoleAppender log4j.appender.console.target=System.err log4j.appender.console.layout=org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n # Set the default spark-shell/spark-sql log level to WARN. When running the # spark-shell/spark-sql, the log level for these classes is used to overwrite # the root logger's log level, so that the user can have different defaults # for the shell and regular Spark apps. log4j.logger.org.apache.spark.repl.Main=WARN log4j.logger.org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver=WARN # Settings to quiet third party logs that are too verbose log4j.logger.org.sparkproject.jetty=WARN log4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle=ERROR log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO log4j.logger.org.apache.parquet=ERROR log4j.logger.parquet=ERROR # SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR # For deploying Spark ThriftServer # SPARK-34128：Suppress undesirable TTransportException warnings involved in THRIFT-4805 log4j.appender.console.filter.1=org.apache.log4j.varia.StringMatchFilter log4j.appender.console.filter.1.StringToMatch=Thrift error occurred during processing of message log4j.appender.console.filter.1.AcceptOnMatch=false 5 - 启动Spark   可以使用以下 shell 脚本启动或停止集群，基于 Hadoop 的部署脚本，并在$SPARK_HOME/sbin以下位置可用：\n sbin/start-master.sh - 在执行脚本的机器上启动主实例。 sbin/start-workers.sh- 在conf/workers文件中指定的每台机器上启动一个工作实例。 sbin/start-worker.sh - 在执行脚本的机器上启动一个工作实例。 sbin/start-all.sh - 如上所述启动一个主节点和多个工作节点。 sbin/stop-master.sh- 停止通过sbin/start-master.sh脚本启动的 master 。 sbin/stop-worker.sh - 停止执行脚本的机器上的所有工作实例。 sbin/stop-workers.sh- 停止conf/workers文件中指定的机器上的所有工作实例。 sbin/stop-all.sh - 如上所述停止主节点和工作节点。    使用jps就可以看到现在正在运行的进程了\n  6 - 启动spark-shell并测试运行一个简单的Scala字数计算程序  启动Spark-shell：  spark-shell  完整代码如下：  1 2 3 4 5 6 7 8  # 接续上次文章中上传的文件 val textFile = sc.textFile(\u0026#34;hdfs:///calvinhaynes/README.txt\u0026#34;) textFile.first() val wordCount = textFile.flatMap(line =\u0026gt; line.split(\u0026#34; \u0026#34;)).map(word =\u0026gt; (word, 1)).reduceByKey((a,b) =\u0026gt; a+b) wordCount.collect() textFile.count() textFile.take(10) :quit    运行效果如下：  结语 作为上一篇文章的补充，简单了解一下Spark这个现在流行的通用云计算框架。\n感谢您看到最后，如果本文对您有所帮助的话，还希望给我一个一键三连（狗头保命），如果对于我和我的文章感兴趣的话，欢迎点一个关注，您会收到我回答和文章的更新通知，也欢迎加入我建立的技术交流群QQ：725133797 讨论交流。\n最后附上我的个人博客站：https://blog.calvinhaynes.top/，欢迎访问和交流\n","description":"基于Docker的Hadoop集群配置Spark并简单使用","id":0,"section":"posts","tags":["Docker"],"title":"基于Docker的Hadoop集群配置Spark并简单使用","uri":"https://blog.calvinhaynes.top/posts/%E5%9F%BA%E4%BA%8Edocker%E7%9A%84hadoop%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AEspark%E5%B9%B6%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"},{"content":"前言 最近上了一门关于云计算\u0026amp;大数据的课，课堂上有留一些大作业，所以我也想借此简单的入门一下这个领域，并记下此文作为总结和回顾，同时也方便让大家一起简单认识一下这门技术。\n这次大作业一的要求就是搭建一个Hadoop的多节点服务器集群，要求是三个节点，一个master和两个slave，老师的建议是虚拟机搭集群，但是由于跑虚拟机占用资源太多（虚拟机加上图形界面本身就很大很吃资源，然后还要创建多个虚拟机，很麻烦），而且Docker容器化虚拟技术的诞生本就是更容易也更适合做服务器集群的（之前有幸学了一点Docker真是赚到了笑死）\n但是仅仅按照步骤搭建这个环境就没什么意思了，所以我也想简单理解一下这些配置文件和一些名词，和大数据的一些思想，在文章的末尾我会添加一个版块专门写我查找的很多优质资料以及我的一些学习见解。\n那么下面我们首先开始搭建步骤的详解，毕竟这才是这个文章的主线！\n搭建思路的顺序图 上图可能有点小，而且未来会有变动，建议大家也在下面这个网站上查看这个思维导图的完整版（感谢知犀思维导图的在线查看的功能，真的很感谢这个开源的思维导图软件）\n链接：https://www.zhixi.com/view/dca65eb3 密码：2426\n 知犀思维导图的官方推荐文案，感兴趣的小伙伴试一试吧，是真的良心！！\n发现一个好用的思维导图软件，知犀思维导图（免费）。有几千个免费优质模板，不用开会员，节点数不限制，直接导出高清无水印图片，还支持导出PDF，Word。很强大很良心，颜值还挺高，知犀有在线版、电脑版，还有手机App，多端云同步，推荐试试：https://www.zhixi.com/\n 1 - 写基础环境的Dockerfile并build一个image Dockerfile如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  # 实验一利用Hadoop搭建服务器集群的基础环境DockerfileFROMubuntu:20.04ARG arch_name=amd64 # 1.备份源列表RUN cp /etc/apt/sources.list /etc/apt/sources.backup.list# 2.把本目录下的sources.list中的镜像源添加到Docker中，下载速度起飞COPY sources.list /etc/apt/sources.list# 3.更新源RUN apt-get update # 翻墙代理# RUN export hostip=$(cat /etc/resolv.conf |grep -oP \u0026#39;(?\u0026lt;=nameserver\\ ).*\u0026#39;) \u0026amp;\u0026amp; \\# export https_proxy=\u0026#34;http://${hostip}:7890\u0026#34; \u0026amp;\u0026amp; \\# export http_proxy=\u0026#34;http://${hostip}:7890\u0026#34;# 设置一些环境变量ENV TZ=Asia/Shanghai \\  LANG=en_US.utf8 \\  LANGUAGE=en_US.UTF-8 \\  DEBIAN_FRONTEND=noninteractive# 安装一些Hadoop集群需要的基本环境和辅助程序RUN apt-get install -y openjdk-8-jdk sudo vim ssh openssl wget openssh-server openssh-client net-tools iputils-ping# pdsh全称是parallel distributed shell，可以并行执行对远程目标主机的操作，利于解决批量执行命令或分发任务的运维需求。# 适用于大批量服务器的配置，部署，文件复制等运维操作。RUN apt-get install -y pdsh \u0026amp;\u0026amp; \\  echo ssh \u0026gt;\u0026gt; /etc/pdsh/rcmd_default# SSH配置RUN ssh-keygen -t rsa -P \u0026#34;\u0026#34; -f ~/.ssh/id_rsa \u0026amp;\u0026amp; \\  cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys \u0026amp;\u0026amp; \\  chmod 600 ~/.ssh/authorized_keys \u0026amp;\u0026amp; \\  chmod 700 ~/.ssh \u0026amp;\u0026amp; \\  echo \u0026#34;service ssh start\u0026#34; \u0026gt;\u0026gt; ~/.bashrc # 安装HadoopRUN wget https://dlcdn.apache.org/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz \u0026amp;\u0026amp; \\  tar -xzf hadoop-3.2.2.tar.gz \u0026amp;\u0026amp; \\  mv hadoop-3.2.2 /usr/local/hadoop \u0026amp;\u0026amp; \\  rm hadoop-3.2.2.tar.gz # 安装ScalaRUN wget https://downloads.lightbend.com/scala/2.12.6/scala-2.12.6.tgz \u0026amp;\u0026amp; \\  tar -xzf scala-2.12.6.tgz \u0026amp;\u0026amp; \\  mv scala-2.12.6 /usr/local/scala \u0026amp;\u0026amp; \\  rm scala-2.12.6.tgz# 安装SparkRUN wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2-scala2.13.tgz \u0026amp;\u0026amp; \\  tar -xzf spark-3.2.0-bin-hadoop3.2-scala2.13.tgz \u0026amp;\u0026amp; \\  mv spark-3.2.0-bin-hadoop3.2-scala2.13 /usr/local/spark \u0026amp;\u0026amp; \\  rm spark-3.2.0-bin-hadoop3.2-scala2.13.tgz# 创建一些目录，一会儿配置Hadoop文件要用到RUN mkdir -p /usr/local/hadoop/hadoop_data/hdfs \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/tmp \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/namenode \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/datanode \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/edits \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/checkpoints \u0026amp;\u0026amp; \\  mkdir -p /usr/local/hadoop/hadoop_data/hdfs/checkpoints/edits# 开放Hadoop相关端口，方便外部进行访问EXPOSE8088 50090 9864 19888 50070 8080CMD [\u0026#34;/bin/bash\u0026#34;]   从上述Dockerfile中不难看出这步仅仅是安装一些必备的环境、配置SSH、声明开放一些端口、创建一些Hadoop的HDFS需要用到的目录，当然Spark和Scala的安装是第二个大作业的要求，我会在下一篇博文分享\n 利用此Dockerfile去build一个image：（不要忽略后面的**“.”**）\n1  docker build -t=\u0026#34;hadoop-mutinode-cluster\u0026#34; .   2 - 配置Docker桥接网络  因为服务器集群相互之间需要连通，所以必须进行网络的配置。\nDocker网络bridge桥接模式，是创建和运行容器时默认模式。这种模式会为每个容器分配一个独立的网卡，桥接到默认或指定的bridge上，同一个Bridge下的容器下可以互相通信的。我们也可以创建自定义bridge以满足个性化的网络需求。\n  创建Docker桥接网络  1  docker network create --driver bridge hadoop-br   以上命令创建了一个名为hadoop-br的bridge类型的网络\n 创建三个Container，也就是三个服务器，并指定网络和端口映射关系  1 2 3 4 5 6  # master节点创建命令如下： docker run -itd --network hadoop-br --name hadoop_master --hostname master --ip 172.18.0.2 --add-host slave1:172.18.0.3 --add-host slave2:172.18.0.4 -p 8088:8088 -p 8080:8080 -p 50090:50090 -p 9864:9864 -p 19888:19888 -p 50070:50070 calvinhaynes412/hadoop-mutinodes-cluster:v1.2.0 # slave1 docker run -itd --network hadoop-br --name hadoop_slave1 --hostname slave1 --ip 172.18.0.3 --add-host master:172.18.0.2 --add-host slave2:172.18.0.4 calvinhaynes412/hadoop-mutinodes-cluster:v1.2.0 # slave2 docker run -itd --network hadoop-br --name hadoop_slave2 --hostname slave2 --ip 172.18.0.4 --add-host master:172.18.0.2 --add-host slave1:172.18.0.3 calvinhaynes412/hadoop-mutinodes-cluster:v1.2.0    查看网络情况  1  docker network inspect hadoop-br   执行上述命令会得到类似下面的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  [ { \u0026#34;Name\u0026#34;: \u0026#34;hadoop-br\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;273d82ad790f475ef14a78bd5f203d3e441f446683a89e01da5b8240aae731a9\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-11-05T07:04:49.300557Z\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.18.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.18.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;1440ea1055bf14ded8c756bea2ad3f185b00e5663e76b1cf382dd08574be4965\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;hadoop_master\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;f193c3bc481b9e447fcffefa50b10519ee6488a34862b51a1f77be52b1d2c922\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;627843643b974c89063fdd8659c6f2f3b00c1e5ad232b56a3a6513d50d30ce06\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;hadoop_slave2\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;1366b734f7579ae61bae3f41ba53a1f2433bd8df9edc115364dc83e7926b0461\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:04\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.4/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;62a874539d08a4074374cf74f75832cb2c2245a7c95e809f36cbf1250e8a49ac\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;hadoop_slave1\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;324e045b4bc61b44967c246fe7ee363582f5cc7c3b78c1327270e3f504ce6ab6\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:03\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.3/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ]   从以上输出不难看出三台机器的ip：\n1 2 3  172.18.0.2 master 172.18.0.3 slave1 172.18.0.4 slave2   可以登录三个Container，尝试互相可不可以ping的通：\n1 2 3 4  # 在每个Container中分别测试能不能ping通另外两台机器，如果ping的通代表网络没问题了 docker exec -it master bash docker exec -it slave1 bash docker exec -it slave2 bash    测试互相SSH免密登录  1 2 3 4 5 6  ping master ping slave1 ping slave2 ssh master ssh slave1 ssh slave2   如果上述均没问题，那么到此为止修改Hadoop配置之前的预备操作就到此结束了\n3 - 配置环境变量 设置一下Hadoop必须用到的环境变量：（将下面这些环境变量配置的键值对写入~/.bashrc）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  #Hadoop Variables export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin export HADOOP_MAPPED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HODOOP_HOME export CLASSPATH=$CLASSPATH:/usr/local/hadoop/lib/*:. export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export HADOOP_OPTS=\u0026#34;-Djava.library.path=$HADOOP_HOME/lib\u0026#34; export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH export HDFS_NAMENODE_USER=root export HDFS_DATANODE_USER=root export HDFS_SECONDARYNAMENODE_USER=root export YARN_RESOURCEMANAGER_USER=root export YARN_NODEMANAGER_USER=root #Hadoop Variables   更新bash配置：\n1  source ~/.bashrc   4 - 配置Hadoop配置文件（核心部分） 在hadoop集群中，需要配置的文件主要包括四个，分别是core-site.xml、hdfs-site.xml、mapred-site.xml和yarn-site.xml，这四个文件分别是对不同组件的配置参数：\n具体参数含义和参数值可以看如下的四个官方文档：（不同版本只要修改docs的下一级/中的版本号即可）\n code-site.xml：https://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-common/core-default.xml hdfs-site.xml：https://hadoop.apache.org/docs/r3.2.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml mapred-site.xml：https://hadoop.apache.org/docs/r3.2.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml yarn-site.xml：https://hadoop.apache.org/docs/r3.2.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml  我的参数配置如下：\n core-site.xml  1 2 3 4 5 6 7 8 9 10 11 12  \u0026lt;configuration\u0026gt; \u0026lt;!--配置namenode的地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://master:9000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 指定hadoop运行时产生文件的存储目录 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/tmp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    hdfs-site.xml  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  \u0026lt;configuration\u0026gt; \u0026lt;!--上传的文件的副本数(数据备份数，缺省值为3)--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- HDFS的webapp允许使用 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.webhdfs.enabled\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- namenode web应用端口地址 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:50070\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--存放namenode所使用的元数据的路径（文件名、副本的数量、每一个块的Datanode的位置）--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/namenode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--namenode 存放 edits 的路径（edits中存储的是HDFS操作的日志记录）--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- SecondaryNameNode的作用是合并fsimage和edits文件。--\u0026gt; \u0026lt;!--但是如果NameNode执行了很多操作的话，就会导致edits文件会很大，那么在下一次启动的过程中， 就会导致NameNode的启动速度很慢，慢到几个小时也不是不可能，所以出现了SecondNameNode。--\u0026gt; \u0026lt;!-- secondary namenode web 监听端口 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.secondary.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:50090\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- secondary namenode 节点存储 checkpoint 目录--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.checkpoint.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/checkpoints\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- secondary namenode 节点存储 edits 目录--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.checkpoint.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/checkpoints/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--DataNode所使用的元数据保存路径--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/datanode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--DataNode 节点存储 edit 文件--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    mapred-site.xml  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  \u0026lt;configuration\u0026gt; \u0026lt;!--上传的文件的副本数--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;2\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- namenode web 监听端口 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:50070\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--namenode 所使用的元数据保存路径设置--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/namenode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--namenode 存放 edits 的路径（edits中存储的是HDFS操作的日志记录）--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- SecondaryNameNode的作用是合并fsimage和edits文件。--\u0026gt; \u0026lt;!--但是如果NameNode执行了很多操作的话，就会导致edits文件会很大，那么在下一次启动的过程中， 就会导致NameNode的启动速度很慢，慢到几个小时也不是不可能，所以出现了SecondNameNode。--\u0026gt; \u0026lt;!-- secondary namenode web 监听端口 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.secondary.http-address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:50090\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- secondary namenode 节点存储 checkpoint 文件目录--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.checkpoint.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/checkpoints\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- secondary namenode 节点存储 edits 文件目录--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.checkpoint.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/checkpoints/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--DataNode所使用的元数据保存路径--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/datanode\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--DataNode 节点存储 edit 文件--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/usr/local/hadoop/hadoop_data/hdfs/edits\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    yarn-site.xml  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  \u0026lt;configuration\u0026gt; \u0026lt;!-- Site specific YARN configuration properties --\u0026gt; \u0026lt;!-- 指定nodeManager组件在哪个机子上跑 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;mapreduce_shuffle\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;org.apache.hadoop.mapred.shuffleHandler\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 指定resourcemanager组件在哪个机子上跑 --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.hostname\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!--resourcemanager web地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;yarn.resourcemanager.webapp.address\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:8088\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;    workers  master slave1 slave2 5 - 将master中的Hadoop配置文件复制到两个slave中 在master的container中命令行敲入以下命令实现将Hadoop配置文件复制到两个slave中：\n1 2  scp -r /usr/local/hadoop/etc/hadoop root@slave2:/usr/local/hadoop/etc scp -r /usr/local/hadoop/etc/hadoop root@slave1:/usr/local/hadoop/etc   6 - 启动所有服务\u0026amp;访问相应的Web服务  格式化NameNode  1  bin/hdfs namenode -format   启动HDFS  1  sbin/start-all.sh   JPS命令查看各节点HDFS运行情况  1  jps   1 2 3 4 5 6  20528 NodeManager 20368 ResourceManager 20065 SecondaryNameNode 19636 NameNode 19791 DataNode 27423 Jps   通过浏览器访问HDFS对外提供的web服务端口   首先要查看端口映射关系，因为创建容器的时候-P将容器开放的端口随机映射到宿主机的一个随机空闲端口上  1  docker container ls     然后就可以根据其中的端口映射关系访问对应的webapp服务（大部分在配置文件中都能找到相应的设置）：\n namenode information的webapp：master(ip):50070 ====\u0026gt; http://localhost:50070   secondnamenode information 的 webapp：master(ip):50090 ====\u0026gt; http://localhost:50090/   datanode information 的 webapp：workers(ip):9864 ====\u0026gt; http://localhost:9864/   YARN的Webapp：resourcemanager url: master(ip):8088 ====\u0026gt; http://localhost:8088/   启动JobHistoryService：bin/mapred --daemon start historyserver \u0026mdash;-\u0026gt; JobHistory url: master(ip):19888 ====\u0026gt; http://localhost:19888/    7 - 简单测试一些基本的HDFS操作  新建一个文件夹  1  bin/hdfs dfs -mkdir /testHDFS    上传一个文件（为了方便我上传的就是hadoop的README文件）  1  bin/hdfs dfs -put /usr/local/hadoop/README.txt /testHDFS    Webapp查看新建的文件夹和文件  8 - 对Hadoop的初步学习 （一）什么是Hadoop？  The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.\n 根据上述官网的说明可以看出Hadoop就是一个分布式处理大数据集的一个框架，他把单服务器存储、处理数据扩展到了多台服务器集群分布式存储、计算数据，减轻了单台服务器的负载，并且提高了性能和稳定性（多台服务器集群互相备份也方便有服务器宕机的时候可以顶上去），并且提供了管理多台服务器集群的手段。\n（二）为什么出现了Hadoop？ 其实不难思考，现代世界最重要的就是数据，面对海量的数据，老旧的单机存储和处理数据的手段已经不适用海量的甚至是无关联的数据集，分布式存储计算已经成为解决这些问题的核心手段，其实仔细思考，现在技术圈比较火的几个名词：微服务，云原生，NoSQL，大数据，分布式，云计算，人工智能，归根结底这些技术都离不开海量数据的存储，计算，分析等等，举例来说，Google搜索引擎每天要存储海量的网页，并且执行自己的分析算法，随着数据量越来越大，就要采用分布式的办法，所以他们先后提出了GFS、NGFS、BigTable，而Hadoop也一步步推出自己相关的解决方案，如下图：\n（三）初探Hadoop Hadoop的核心架构，就是HDFS和MapReduce。其中HDFS（Hadoop File System）是为了存储海量的数据来存在的，而MapReduce是为海量数据提供了一个计算框架\n1 - HDFS HDFS主要有三个要素：NameNode、DataNode、Client\n NameNode：Master节点，相当于所有DataNode的管理者，Namenode会将文件系统的一系列元数据（元数据这个词非常常见，它的意思就是表示数据的数据）存在其中，包括每个文件Block在DataNode中的信息。 DataNode：是Slave节点（从节点），是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。 **Client：**切分文件；访问HDFS；与NameNode交互，获得文件位置信息；与DataNode交互，读取和写入数据。  Block（块）：Block是HDFS中的基本读写单元；HDFS中的文件都是被切割为block（块）进行存储的；这些块被复制到多个DataNode中；块的大小（通常为64MB）和复制的块数量在创建文件时由Client决定。  2 - MapReduce MapReduce就是总结了大数据算法的通用特点之后造的轮子，关于MapReduce的介绍和讲解网上的例子都大差不差，我推荐下面这几个介绍和讲解\n 官网：https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html Google的MapReduce论文讲解：https://zhuanlan.zhihu.com/p/34849261 五分钟搞懂Hadoop：https://zhuanlan.zhihu.com/p/20176725  结语 感谢您看到最后，如果本文对您有所帮助的话，还希望给我一个一键三连（狗头保命），如果对于我和我的文章感兴趣的话，欢迎点一个关注，您会收到我回答和文章的更新通知，也欢迎加入我建立的技术交流群QQ：725133797 讨论交流。\n最后附上我的个人博客站：https://blog.calvinhaynes.top/，欢迎访问和交流\n参考资料 https://zhuanlan.zhihu.com/p/25472769\nhttps://www.cnblogs.com/upupfeng/p/13616125.html\nhttps://hadoop.apache.org/docs/r3.2.2/\nhttps://zhuanlan.zhihu.com/p/54994736\n","description":"利用Docker搭建一个多节点服务器集群","id":1,"section":"posts","tags":["Docker"],"title":"利用Docker搭建一个Hadoop Mutinode Cluster","uri":"https://blog.calvinhaynes.top/posts/%E5%88%A9%E7%94%A8docker%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AAhadoop-muti-node-cluster/"},{"content":"前言 自从学习了Docker，我就无处施展自己的才华了，突然想起之前学习MIT6.S081课程的时候环境搭建完后就一直在吃灰，再加上我突然联想到之前搭建的code-server（点这里），所以我突然有了个大胆的想法，搭建一个Docker的MIT6.S081实验环境，并且采用code-server的形式，达成一个开箱即用的效果，甚至可以挂到云服务器（阿里云学生机）上，实现随时随地使用code-server进行实验，有灵感的时候随时掏出IPAD或者手机就可以实验搞起，实在是太香了，而且以后其他CSLab也可以采用相似的方案，那么下面我们就开始吧。\n没有了解过Docker的小伙伴我给出以下几个链接供大家学习和参考\n Docker从入门到实践文档（非常详尽） 油管视频列表（科学上网） Dockerfile参考文档  Dockerfie 官方文档：https://docs.docker.com/engine/reference/builder/ Dockerfile 最佳实践文档：https://docs.docker.com/develop/develop-images/dockerfile_best-practices/ Docker 官方镜像 Dockerfile：https://github.com/docker-library/docs    如何按需正确食用本文\n 仅仅想直接使用我搭建好的环境的童鞋请直接移步到使用篇，利用Docker可以直接pull我的Regisry（环境比较大，国外服务器很慢，后面我会说其他解决方案），然后直接进行MIT6.S081的实验 想学习Docker搭建环境的童鞋可以慢慢看环境搭建步骤  效果演示 环境搭建步骤 通过不断的尝试，我觉得这种方案可以作为做国外CSLab的通用方案，只要写好相应的Dockerfile就可以了，code-server和其他一些常见的比如镜像源的设置、使用的linux发行版等等是通用的，这些保留，然后剩下的部分就专注于在Dockerfile中搭建相应国外CSLab的环境就可以了，基于此思路，我们进行下面的搭建步骤。（下面一步步按照我的思路来走，之后你想搭建自己的其他实验环境，就按照这样思路向下进行就可以了）\n1 - 首先准备好各种搭建环境的工具   首先我是Windows系统，所以下载了Docker Desktop\n  简单配一些国内的Docker Registry镜像源（点开设置中Docker Engine就行了）\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14  { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://registry.docker-cn.com\u0026#34;, \u0026#34;http://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://xzahxrmt.mirror.aliyuncs.com\u0026#34; ], \u0026#34;insecure-registries\u0026#34;: [], \u0026#34;debug\u0026#34;: false, \u0026#34;experimental\u0026#34;: false, \u0026#34;features\u0026#34;: { \u0026#34;buildkit\u0026#34;: true } }     windows原生的命令行终端太拉了，所以下载他们新出的Windows Terminal，样子好看了不少，还能开多个Tab标签，还能定制化样式，确实好用（附上youtube上的美化教程）\n  2 - 然后进行MIT6.S081环境搭建的调研和实践  首先肯定是官网的环境搭建说明书是第一位要看的：https://pdos.csail.mit.edu/6.828/2020/tools.html 结果发现搭建问题很多，我使用的是ubuntu20.04LTS，官方教程对应ubuntu的部分搭建起来一大堆问题。 然后我就开始互联网冲浪寻找其他人分享的环境搭建的教程，自己先简单开个Docker测试每个教程的环境搭建是否有效，最终结合多家教程和自己的思考，拿到了正确的环境配置方式，并写了对应的Dockerfile，具体内容如下（没一步操作我都写好注释了，可以先看完上面的Docker从入门到实践中的Dockerfile部分然后再看这里进行理解）：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64  FROMubuntu:20.04ARG arch_name=amd64 # 前几步因为针对本实验依赖不全的原因问题百出，所以放弃了，还是ubuntu20.04官方镜像源对于MIT6.S081所需依赖最全面# 1.备份源列表# RUN cp /etc/apt/sources.list /etc/apt/sources.backup.list# 2.把本目录下的sources.list中的镜像源添加到Docker中，下载速度起飞# COPY sources.list /etc/apt/sources.list# 3.更新源# RUN apt-get update # 创建一个mit6s081的用户和其home目录RUN useradd -m mit6s081 \u0026amp;\u0026amp; \\  echo \u0026#34;root ALL=(ALL) NOPASSWD: ALL\u0026#34; \u0026gt;\u0026gt; /etc/sudoers \u0026amp;\u0026amp; \\  echo \u0026#34;mit6s081 ALL=(ALL) NOPASSWD: ALL\u0026#34; \u0026gt;\u0026gt; /etc/sudoers  # 设置一些环境变量ENV TZ=Asia/Shanghai \\  LANG=en_US.utf8 \\  LANGUAGE=en_US.UTF-8 \\  LC_ALL=en_US.UTF-8 \\  DEBIAN_FRONTEND=noninteractive# MIT6.S081 Lab所用依赖# 1.安装RISC-V交叉编译工具和一些其他的常用工具RUN apt-get update \u0026amp;\u0026amp; \\  apt-get install -y sudo locales git wget vim build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu libpixman-1-dev gcc-riscv64-unknown-elf libglib2.0-dev pkg-config# 2.安装QEMU和配置QEMURUN wget https://download.qemu.org/qemu-5.1.0.tar.xz RUN tar xf qemu-5.1.0.tar.xz RUN cd qemu-5.1.0 \u0026amp;\u0026amp; \\  ./configure --disable-kvm --disable-werror --prefix=/usr/local --target-list=riscv64-softmmu \u0026amp;\u0026amp; \\  make \u0026amp;\u0026amp; \\  make install# 下载code-server并安装RUN apt-get install -y aria2 \u0026amp;\u0026amp; \\  aria2c https://github.com.cnpmjs.org/cdr/code-server/releases/download/v3.12.0/code-server_3.12.0_${arch_name}.deb \u0026amp;\u0026amp; \\  dpkg -i code-server_3.12.0_${arch_name}.deb# 切换用户mit6s081USERmit6s081# 下载一些code-server的插件RUN mkdir /home/mit6s081/extensions# 1.Markdown ExtensionRUN code-server --install-extension yzhang.markdown-all-in-one# 2.Cpp ExtensionADD cpptools-linux.vsix /home/mit6s081/extensionsRUN code-server --install-extension /home/mit6s081/extensions/cpptools-linux.vsix# 3.Material Theme ExtensionRUN code-server --install-extension equinusocio.vsc-material-theme # 切换回Root用户，拥有最高权限USERrootRUN apt-get update# 暴露8848端口，用于code-server本地运行的端口EXPOSE8848# 设置code-server密码ENV PASSWORD=mit6s081 USERmit6s081CMD [ \u0026#34;code-server\u0026#34;, \u0026#34;--bind-addr\u0026#34;, \u0026#34;0.0.0.0:8848\u0026#34;, \u0026#34;--auth\u0026#34;, \u0026#34;password\u0026#34; ]   写好Dockerfile之后，直接docker build -t \u0026lt;镜像名\u0026gt;:\u0026lt;版本号/标签\u0026gt; .就构建好镜像了，注意后面那个.可不能省略，具体原因看这里   之所以创建了两个用户也是为了大家在使用环境的时候专注于使用当前环境，而不给大家root用户修改环境的权限，所以如果你遇到了使用apt-get update等指令时给出denied的报错正是说明了这点。\n当然如果你想自己增加一些功能，也可以本地使用命令docker exec -u root -it \u0026lt;Container名字\u0026gt; /bin/bash进入你创建的container中，然后你可以自定义这个Container的环境，然后commit到镜像上，如果功能不错提高实验幸福感的话，欢迎知乎私信或者Github上提Issue。\n 3 - 一些环境搭建中遇到的坑  被选择时区的环节卡住  1 2 3 4 5 6 7 8  Please select the geographic area in which you live. Subsequent configuration questions will narrow this down by presenting a list of cities, representing the time zones in which they are located. 1. Africa 4. Australia 7. Atlantic 10. Pacific 13. Etc 2. America 5. Arctic 8. Europe 11. SystemV 3. Antarctica 6. Asia 9. Indian 12. US Geographic area:   可以通过配置环境变量，来跳过这个步骤\n1  ENV DEBIAN_FRONTEND=noninteractive   RUN的使用不当，导致环境搭建过程中一直出错  主要是最初不理解Dockerfile，顺着指令说明书就开始莽了，后来才发现RUN指令每次执行会在当前image之上的新的一层中执行后面的命令并提交结果，这样就导致前后有关联的指令执行总是报错（原因就是他们本就应该是一条流程下来的，现在拆分成不同层了当然会出错），所以我才学会用 \u0026amp;\u0026amp;和\\（反斜杠）将单个 RUN 指令延续到下一行。\n比如下面这几行例子：\n1 2 3 4  RUN cd qemu-5.1.0 \u0026amp;\u0026amp; \\  ./configure --disable-kvm --disable-werror --prefix=/usr/local --target-list=riscv64-softmmu \u0026amp;\u0026amp; \\  make \u0026amp;\u0026amp; \\  make install  如果不用\u0026amp;\u0026amp;和\\关联各行的话，比如第一行cd到那个qemu-5.1.0目录了，下一行**./configure执行的时候在新的一层了，就一定会报错不存在./configure**（因为这个configure配置qemu的可执行文件就在qemu-5.1.0目录下）\n使用篇 1 - 方式一：DockerHub 首先pull下来我的Docker镜像：  由于DockerHub用的是国外的服务器，所以很慢很慢，但是就一行命令，比较容易 镜像地址在这里：https://hub.docker.com/repository/docker/calvinhaynes412/mit6.s081/tags?page=1\u0026amp;ordering=last_updated 最新版本的pull镜像的命令如下：  1  docker pull calvinhaynes412/mit6.s081:v1.3.1   然后去Github上Fork我上传的MIT6.S081原版纯净的实验环境  这样你就能自己git管理自己的实验代码了，其实我就是把官方的git仓库自己上传了，主要是由于MIT pdos官方没有放出来这个2020实验的源代码不方便Fork之后直接自己使用，所以我转载了官方的2020实验源代码，是方便大家直接Fork下来自己做实验，并且我加了一个MIT的开源许可协议。\n  项目地址：https://github.com/CalvinHaynes/MIT6.S081-2020-labs（） Fork完之后clone到你本地的一个文件夹里面（重点，之后创建Docker的Container的时候需要使用）   想在这里顺便介绍一下我自己学习此Lab整理笔记和实验解决方案的一个仓库，供大家学习参考，如果有帮助的话希望给我点一个STAR\n  GitHub项目地址：https://github.com/CalvinHaynes/MIT6.S081-2020Fall\n  码云版本：https://gitee.com/CalvinHaynes/MIT6.S081-2020Fall\n  在项目中涉及了每个实验（如果我能坚持做完的话，我相信我可以）的实验解决代码、实验笔记、课堂笔记、课堂小练习、一些学习操作系统优质的资料等等。\n 创建一个Container  点击RUN   配置Container   这里的Volumes配置你可以理解为将Host Path中的文件目录挂载在此Container中，挂载在Container的具体位置就是这里配置的Container Path（这里就直接配置成我图中写的路径，因为我已经在.gdbinit设置过了，如果你修改为其他位置的话，就修改/home/mit6s081/.gdbinit中的内容为add-auto-load-safe-path \u0026lt;你设置的Container Path\u0026gt;/.gdbinit）\nVolumes简单理解就是主机目录挂载到容器上\n 2 - 方式二：阿里云镜像仓库  由于DockerHub服务器在国外，实在难以忍受它的速度，有一天偶然发现，阿里云竟然有容器镜像服务，NICE！冲！！！ 这个速度简直飞快，实测大约不到一分钟就pull下来了 先在Docker Engine中加入阿里云的Docker镜像，前面的Docker Engine设置中的\u0026quot;https://xzahxrmt.mirror.aliyuncs.com\u0026quot;就是阿里云的镜像加速器 运行指令：  1  docker pull registry.cn-beijing.aliyuncs.com/calvin_haynes/mit6.s081:release-v1.0.0    之后创建一个Container的方法和上述一致  3 - 开始做实验吧！ 如果你也是配置的8848端口，那么直接点击http://localhost:8848/(密码是==mit6s081==哦)，就可以进入在线的Vscode进行愉快（狗头保命）的MIT6.S081实验了！！\n完整的命令行使用教程(服务器端和本地Linux系统用户看这里)  安装docker 配置阿里云镜像加速器（以下命令针对ubuntu）  1 2 3 4 5 6 7 8  sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://xzahxrmt.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker   pull镜像（最新版本，之后版本更新的通知我会在评论区说明，记得偶尔来看看）  1  docker pull registry.cn-beijing.aliyuncs.com/calvin_haynes/mit6.s081:release-v1.3.1   clone实验源代码(我还会慢慢在这个项目中增加我学习过程中的笔记和实验代码等资料,如果对你有帮助的话,希望帮我点个STAR哦)  1  git clone https://github.com/CalvinHaynes/MIT6.S081-2020-labs \u0026lt;放实验文件的任何你想要放的位置\u0026gt;   创建Container（-u 0:0是为了保证Container中的root用户和本机的root用户权限一致,不过其实不建议用root权限，所以如果本机和Container的其他非root用户有相同的uid的话最好 -u uid:uid）  1  docker run -p 8848:8848 --name=mit6.s081 -u 0:0 -v \u0026#34;\u0026lt;刚才clone的项目的位置\u0026gt;:\u0026lt;设置一个Container中的位置映射到前面的clone的项目的位置\u0026gt;\u0026#34; registry.cn-beijing.aliyuncs.com/calvin_haynes/mit6.s081:release-v1.3.1   本地用户浏览器访问 http://localhost:8848/ 密码： mit6s081. 服务器端用户浏览器访问http://\u0026lt;服务器公网ip\u0026gt;:8848/ 密码： mit6s081.  结语 这虽然只是一个MIT6.S081的Docker环境搭建教程，但是同时也是以后搭建其他实验环境的思路，如果学会了这一套思路和手段，那么以后后搭建任何环境都是唾手可得的！！\n关于MIT6.S081的实验解析和课程笔记未来都会逐渐在我的项目中更新，欢迎大家关注这个项目，关于此Docker，还有很多可以优化的地方，我会同步更新Dockerfile，Docker阿里云镜像/官方镜像，敬请期待。\n感谢您看到最后，如果本文对您有所帮助的话，还希望给我一个一键三连（狗头保命），如果对于我和我的文章感兴趣的话，欢迎点一个关注，您会收到我回答和文章的更新通知，也欢迎加入我建立的技术交流群QQ：725133797 讨论交流。\n最后附上我的个人博客站：https://blog.calvinhaynes.top/，欢迎访问和交流\n","description":"一个玩转国外CSLab的通用环境搭建方案（附我的搭建好的MIT6.S081环境）","id":2,"section":"posts","tags":["操作系统","Docker","Vscode","CSLab"],"title":"一个玩转国外CSLab的通用环境搭建方案（附我的搭建好的MIT6.S081环境）","uri":"https://blog.calvinhaynes.top/posts/cslab/"},{"content":"前言 这是一个我正在使用的软件清单系列文章，涵盖了时间管理，高效率开发工具，系统优化软件，写文档工具流等。\n之所以写这篇文章，很大一部分原因是想和大家分享一下我的效率软件清单，另一个原因是也为自己下次重装系统做一个保障，免得忘记什么。\n下面我们就正式开始介绍吧，目录我会分好类的，每个超链接都指向一些我认为的非常好的资源以及各个软件的下载地址等等的信息，大家按照自己想要看的点进去就可以了。\n 这可能是我的一个专栏系列（分享我使用的所有的有趣和高效率的软件或插件，网页等）\n windows 系统优化工具 1 - 分区助手  想必大家都被分区弄得很头痛吧，在装系统时 C 盘分的太小了，现在 C 盘红了，还不好清理，那么这款分区助手就能完美解决你的问题 图形化界面相当友好，电脑小白也能操作 附上分区助手官网的使用手册：https://www.disktool.cn/jiaocheng/index.html  2 - CCleaner：电脑管家  虽然网上骂声一片，说 CCleaner 是流氓软件，但是我依旧爱他，爱他简约而不简单的功能 CCleaner 的功能列表如下：  垃圾清理 驱动更新 注册表清理（超级强的功能） 卸载程序 管理 PC 启动项 重复文件查找 系统备份和还原 Cookie 和浏览器插件管理 等等   软件界面如下：  结语 好的工具只是方便我们管理自己的 PC 或者便于开发而已，千万不能陷入工具的陷阱，人和动物最大的区别就是学会了制造工具，但是过分依赖于工具也会毁了一个人，在使用工具时要保持一个态度就是：对于自己十分明确的功能勇敢的使用和尝试，对于自己不明确的功能先去学习原理，再结合搜索引擎上的经验慢慢投入使用。\n最后希望大家按需取用上述的软件，玩的愉快！！\n 未来我还会持续更新，在清单中添加更加有趣的软件，敬请期待！！！  ","description":"windows系统优化工具清单","id":3,"section":"posts","tags":["软件清单"],"title":"属于每一个程序猿和学生的一份高效率软件清单--第三弹:windows系统优化工具（持续更新）","uri":"https://blog.calvinhaynes.top/posts/software_3/"},{"content":"前言 这是一个我正在使用的软件清单系列文章，涵盖了时间管理，高效率开发工具，系统优化软件，写文档工具流等。\n之所以写这篇文章，很大一部分原因是想和大家分享一下我的效率软件清单，另一个原因是也为自己下次重装系统做一个保障，免得忘记什么。\n下面我们就正式开始介绍吧，目录我会分好类的，每个超链接都指向一些我认为的非常好的资源以及各个软件的下载地址等等的信息，大家按照自己想要看的点进去就可以了。\n 这可能是我的一个专栏系列（分享我使用的所有的有趣和高效率的软件或插件，网页等）\n 程序猿写文档必备工具箱 1 - Snipaste：截图软件  这绝对是综合看来我用过所有 windows 下截图软件最棒的了，所有的截图功能都有，像全屏截图、窗口截图，自定义像素截图等等基本功能都有。 最牛的功能是它的贴图功能，不知道大家有没有遇到过这样一种情况：假如上网课的时候，老师讲的下部分是关于上一张 PPT 的，但是你手中还没有 PPT，或者你想对比一下之前的 PPT 来学习，那么这个时候贴图就发挥其作用了，示例如下：（你还可以发挥你的其他想象利用这个功能）   可以设置的选项如下：（==你可以在控制中自定义各个功能的快捷键，设置成你熟悉的==）  2 - GifCam：一款录制 GIF 的软件  看了上面的 GIF 图，是不是也在奇怪我这些图是怎么自己做的，那么这就向您介绍这款软件：GIFCam，这是一款可以录制 GIF 动图的软件，短小精悍，仅仅只有录制 GIF 的功能，你可以设置输出文件的 FPS，自定义录制的窗口大小或者全屏等等。  3 - PicX 图床：一个开源作者写的开源图床  其实这个不能算是软件，但由于 chrome 浏览器可以直接把这个网站直接打包成一个应用在本地，也算个软件把。 这个开源图床目前还在优化和更新中，作者也十分努力的在开发和维护这个项目 这个图床就是利用你自己建的 Github 库存储图片，然后提供图片的管理和 Markdown+CDN 格式的自动转换，上传图片之后直接复制就可以放在你的 md 文档中了，着实挺方便，而且界面 UI 和交互也都很不错。 使用情况如下：（感谢作者：https://xpoet.cn/）  结语 好的工具只是方便我们管理自己的 PC 或者便于开发而已，千万不能陷入工具的陷阱，人和动物最大的区别就是学会了制造工具，但是过分依赖于工具也会毁了一个人，在使用工具时要保持一个态度就是：对于自己十分明确的功能勇敢的使用和尝试，对于自己不明确的功能先去学习原理，再结合搜索引擎上的经验慢慢投入使用。\n最后希望大家按需取用上述的软件，玩的愉快！！\n 未来我还会持续更新，在清单中添加更加有趣的软件，敬请期待！！！  ","description":"程序猿写文档必备工具箱清单","id":4,"section":"posts","tags":["软件清单"],"title":"属于每一个程序猿和学生的一份高效率软件清单--第二弹:程序猿写文档必备工具箱（持续更新）","uri":"https://blog.calvinhaynes.top/posts/software_2/"},{"content":"前言 这是一个我正在使用的软件清单系列文章，涵盖了时间管理，高效率开发工具，系统优化软件，写文档工具流等。\n之所以写这篇文章，很大一部分原因是想和大家分享一下我的效率软件清单，另一个原因是也为自己下次重装系统做一个保障，免得忘记什么。\n下面我们就正式开始介绍吧，目录我会分好类的，每个超链接都指向一些我认为的非常好的资源以及各个软件的下载地址等等的信息，大家按照自己想要看的点进去就可以了。\n 这可能是我的一个专栏系列（分享我使用的所有的有趣和高效率的软件或插件，网页等）\n 程序猿高效开发工具 1 - JetBrains Toolbox：JetBrains 家的工具箱  自从用了 JetBrains 家的 IDEA，就爱上了他们家 IDE 的风格，目前也是离不开了，写各种语言程序的时候都是优先找他们家的 IDE，优秀的插件和特别 Geek 风的界面确实让人眼前一亮，JetBrains 推出的这款 JetBrains Toolbox 集成了 JetBrains 家所有工具的下载，更新，项目管理，对于喜欢 JetBrains 家 IDE 的朋友们确实方便了许多。\n只需要创建一个 JetBrains 的文件夹，在设置中设置其为下载安装位置，就可以将所有 JetBrains 家的 IDE 集中在一个文件夹中，对于要重装系统的朋友在设置了 IDE 中的插件和配置同步后，直接下载 JetBrains Toolbox，也能免去很多麻烦。\n2 - Vscode：轻量代码编辑器 虽然 JetBrains 家的 IDE 十分好用，但是对于简单的代码编辑工作，调试小段代码，确实显得就不太方便了，这时候一个优秀的代码编辑器就能胜任这些快速编辑代码的工作。\n市面上主流的有 Sublime Text，Vscode，NotePad ++，Atom，Vim 等等，但是 Vscode 现在丰富的插件以及优秀的远程开发的能力确实突出。\n所以跌跌撞撞最终还是选择了拜倒在 Vscode 的石榴裙下。\n有关于 Vscode，我还写了一篇利用 code-server 和阿里云搭建在线版 Vscode 的文章，可以让你在网页，手机，Ipad 上随时随地运行 Vscode。\nhttps://zhuanlan.zhihu.com/p/379632978\n3 - uTools：桌面快速工具箱 uTools 是一个极简、插件化的现代桌面软件，通过自由选配丰富的插件，打造得心应手的工具集合。\n通过快捷键（默认 alt + space ）就可以快速呼出这个搜索框。你可以往输入框内粘贴文本、图片、截图、文件、文件夹等等，能够处理此内容的插件也早已准备就绪，统一的设计风格和操作方式，助你高效的得到结果。\n一旦你熟悉它后，能够为你节约大量时间，即用即走、不中断、无干扰，让你可以更加专注地改变世界。\n这是一家创业公司做的一款软件，这种一切皆插件，呼出即使用的感觉是前所未有的，大大提高了开发效率\n在插件中心中可以下载很多高效的插件，比如思维导图，Markdown 文档，快速打开最近的项目，翻译，基于 Everything 的搜索，快速打开 PC 上的任何一款软件\n==关于高效的插件未来我应该会单独分享。==\n4 - Termius：SSH 终端  这是一个我目前用过的所有的 SSH 终端中最好的一个，它不仅美观，而且跨平台，对于移动端的适配手势简直不要太香，而且申请 Github 学生包还可以免费享用更多的高级特权（Github 学生包所有的特权 ） 我之前写过一篇文章就有介绍过这个软件，大家有兴趣也可以去看看：https://zhuanlan.zhihu.com/p/379632978 以下是软件界面的图片（可以自定义终端的字体和颜色风格等）（全平台通用和同步，包含 Android，IOS，Windows，MacOS，Linux）   支持 SFTP 功能，NICE！！！  ![GIF 2021-6-10 16-34-08](https://cdn.jsdelivr.net/gh/CalvinHaynes/ImageHub@main/BlogImage/GIF 2021-6-10 16-34-08.1n12dp0c16ow.gif)\n5 - Beyond Compare：文件对比软件   Beyond Compare 是一款功能强大而且十分实用的文件对比软件，同时也能一定程度的对文件进行整理及操作，对于电脑中文件较为繁杂且有较多重复模糊不清的电脑使用者尤为适合。\n  它的对比功能是真的很强大，包括文件夹，文本，表格，图片等等对比他都可以实现。\n  我的使用场景：\n 仿写别人或者优秀网站的网页代码时，没有达成预期效果时，两边对比快速定位我的问题 对比一些功能相同但是性能有差别的代码的时候 对比图片，表格信息，文件夹（需要一致性时找不同用）    ==检测到差异时：==\n6 - Github Desktop：迄今为止最好的 Git GUI 工具  你是否为写 Git 命令烦恼，找了很多图形化处理工具，但是都不是很人性化，而且界面丑而差，那么 Github Desktop 这就来了，包您满意诶嘿嘿。 Github Desktop 是 Github 官方开发的 GIthub 图形化软件，就冲这一点，你应该就能知道这个软件应该很好用了吧，毕竟是官方的，起码针对 Github 的支持是杠杠滴 具体使用情况我就不细说了，这里附上使用指南：https://docs.github.com/cn/desktop/installing-and-configuring-github-desktop/overview/getting-started-with-github-desktop ==简单的界面演示如下：==  7 - WireShark：最牛的开源免费网络封包分析工具  软件正如其名字一样，在网线中深潜的鲨鱼。 此软件的作用就是抓包，分析网络中各种协议栈各层的数据包，并可以通过一些过滤表达式得到我们需要拿来分析的数据包（比如分析TCP/IP，HTTP，UDP等） 使用此软件可以实现  网络管理员检查网络 学习计算机网络，通过抓包深刻理解TCP/IP协议栈 Socket编程测试 测试工程师使用其测试软件   利用WireShark测试TCP/IP三次握手，四次挥手   wireshark与对应的OSI七层模型  8 - Postman：模拟HTTP/HTTPS请求工具  Postman是谷歌开发的一款网页调试和接口测试工具，能够发送任何类型的http请求，支持GET/PUT/POST/DELETE等方法。Postman非常简单易用，可以直接填写URL，header，body等就可以发送一个请求，用来测试api接口非常方便。（对于现在各种浏览器都自动把http请求转换为HTTPS请求的情况，用于测试HTTP请求是个很不错的选择） postman快速上手视频教程推荐（科学上网）：https://www.youtube.com/watch?v=VywxIQ2ZXw4\u0026amp;list=PL6YJmTsHJFpGEDbyDCMFXoC42_WQYJPj  9 - Windows Terminal：windows命令行的崛起 结语 好的工具只是方便我们管理自己的 PC 或者便于开发而已，千万不能陷入工具的陷阱，人和动物最大的区别就是学会了制造工具，但是过分依赖于工具也会毁了一个人，在使用工具时要保持一个态度就是：对于自己十分明确的功能勇敢的使用和尝试，对于自己不明确的功能先去学习原理，再结合搜索引擎上的经验慢慢投入使用。\n最后希望大家按需取用上述的软件，玩的愉快！！\n 未来我还会持续更新，在清单中添加更加有趣的软件，敬请期待！！！  ","description":"程序猿高效开发工具系列","id":5,"section":"posts","tags":["软件清单"],"title":"属于每一个程序猿和学生的一份高效率软件清单--第一弹:程序猿高效开发工具（持续更新）","uri":"https://blog.calvinhaynes.top/posts/software/"},{"content":"前言 ​\t上课想练练数据结构与算法？或者就是想玩玩儿Vscode？或者有一个自己的服务器，但是觉得没有利用到极致？那么这篇文章将带你搭建一个在线版的Vscode，利用浏览器实现全平台使用Vscode，管你什么手机，Pad，电脑，板砖，咳咳，整就完了！！！\n​\t文章中所有的超链接都是很不错的资源，建议都要仔细看看，为了不让文章那么太长，所以我用了不少超链接。\n 本文搭建环境：开源项目code-server，一台服务器（至少一核2G才能有比较流畅的效果）\n 如果本文对你有帮助的话，还望关注，点赞，转发，收藏，谢谢咯。\n（一）运行效果  这个Vscode在线版是运行在我买的阿里云学生机的9999端口的，毕竟9.9一月，对于学生党很友好，我的个人博客也搭在上面的，性能一般，但是也很够用了。\n （二）基础配置 1 - 下载code-server到服务器上  进到服务器的SSH中，这个只要你买了服务器应该都可以用SSH的，服务器还没买的，也不会用服务器的，看以下几篇文章（其实不限制与阿里云的，不是推广阿里云哈，其他云怎么用大家自行选购，因为我用的是阿里云，所以这几篇文章也都是阿里云的一些使用教程）：\n https://zhuanlan.zhihu.com/p/368487727 https://www.zhihu.com/search?type=content\u0026amp;q=%E9%98%BF%E9%87%8C%E4%BA%91%E5%AD%A6%E7%94%9F%E6%9C%BA%E6%95%99%E7%A8%8B（自己挑着看） https://blog.csdn.net/u011002997/article/details/83933365  官网上应该也还有比较完善的使用手册啥的，深入玩一下的话，建议自己多研究研究，上面这几篇文章也是我大体看上去不错的，要想明白究竟怎么用的还是要自己用好搜索引擎。\n wget https://github.com/cdr/code-server/releases/download/v3.10.2/code-server-3.10.2-linux-amd64.tar.gz  这一步下载速度可能会很慢，甚至中途失败，可以考虑挂代理，不会Linux下挂代理的，看我下面的骚操作\n 当然，你最好有一个梯子，这样总归是要更快和更稳定的。\n下面我将演示如何在Windows下下载code-server再传到服务器上：\n  首先我想介绍一下我使用过那么多的SSH最好用的一款软件：Termius\n​\t这个软件是真正的全平台，而且简直是我这种颜值控福利，终端各种皮肤，贼好看，如果你有幸申请到Github学生包的话，还有其他不少福利。\n​\t关于Termius的使用教程\n  在Windows下载code-server的压缩包\n点击这个链接\n再点这个，就开始下载了\n  下载完压缩包之后，找到下载的位置，然后就要介绍Termius的SFTP功能\n​\t选中你的服务器\n  ​\t先找到你本地压缩包的网址，选中你本地的压缩包，直接拖到服务器上就行（哎，真不错，我就是玩儿）\n![GIF 2021-6-10 16-34-08](https://cdn.jsdelivr.net/gh/CalvinHaynes/ImageHub@main/BlogImage/GIF 2021-6-10 16-34-08.1n12dp0c16ow.gif)\n传过去之后现在你可以到你的服务器中ls -a一下，看看它在不在  ​\t那么以上就是下载的全部内容了\n2 - 解压安装试运行（运行部分可以先不弄，下一步的更好用）  解压  tar -xvzf code-server-3.10.2-linux-amd64.tar.gz  可以改个名  mv code-server-3.10.2-linux-amd64 code-server  运行试下（建议先看下参数列表）  PS：得确保你开了9999端口，下面是我的服务器防火墙配置\n 为啥不用8080端口？戳这\n cd code-server export PASSWORD=\u0026quot;你想设置的密码\u0026quot; ./code-server --port 9999 --host 0.0.0.0 --auth password   –port 9999 指定端口，缺省时为 8080 –host 0.0.0.0 允许公网访问，缺省时为 127.0.0.1，只能本地访问 –auth password 指定访问密码，可通过 export 命令设置，参数为 none 时不启用密码    可以看一下参数列表  ./code-server --help  运行后，打开 Chrome 访问“服务器公网IP:端口”，效果图：   服务器公网IP去哪里查？ 戳这\n （三）高级配置 ​\t我们都知道Linux是可以写shell脚本的，那么为了简化以上操作，也为了让其根据我们意愿后台运行或者终止，我们着手写两个脚本，start.sh和shut.sh(脚本是要写在code-server目录的奥)\n脚本执行目标\n  start.sh\n 开启code-server，后台运行该进程 记录当前进程的PID，也专门记录一个日志log文件便于以后查看 将PID存到文件里面  #start.sh export PASSWORD=\u0026quot;412523\u0026quot; nohup ./code-server --port 9999 --host 0.0.0.0 --auth password \u0026gt; test.log 2\u0026gt;\u0026amp;1 \u0026amp; echo $! \u0026gt; save_pid.txt   shut.sh\n 读文件中的PID 杀死进程  #shut.sh kill -9 'cat save_pid.txt'   （四）Ios端/IpadOS端的最佳使用方式  本来配置完以上，我们用任何设备，只要用浏览器就可以使用了，但是Ios端和IpadOS端有一个可以更加沉浸体验的软件，推荐给大家\n  以下是使用方法：  选好点Save就可以了，访问效果就如第一步运行效果的图\n（五）使用流程总结  SSH登入服务器 cd code-server ./start.sh 浏览器直接访问网址/Apple系列产品的serveditor 关了，免得一直占用我的服务器：./shut.sh  （六）参考资料 在Ipad上使用Vscode\n","description":"使用code-server搭建在线运行的Vscode","id":6,"section":"posts","tags":["Vscode"],"title":"上课摸鱼必备 -- Vscode网页版的搭建教程","uri":"https://blog.calvinhaynes.top/posts/vscode-online-build/"},{"content":"前言 经过种种尝试，还是决定选择了Hugo作为了搭建个人博客的框架，Hugo是目前可以搭建个人博客的框架中部署最快的，而且坑也相对很少，不过还是有的，近几天折腾了不少东西，也终于算是初步搭建完了Hugo+Zoo主题的个人博客\n在本文中我会讲解部署的详细过程，也会科普一些部署中的原理，毕竟我也刚刚接触，所以有些说的不对的地方也希望评论区的大佬来勘误，谢谢啦。\n如果遇到部署问题，欢迎在评论区打出你的问题，我和知乎这个优秀社区的所有人都有可能回答你的疑问哦，本文如果对你有帮助的话，还希望多多点赞收藏转发，谢谢啦。\n1 - 使用Hugo创建静态网站实战 1、安装Hugo 博主用的是Windows系统，所以安装过程中我会基于Windows进行讲解，有关其他操作系统的安装方法可以参考官方的文档\nWindows下的Hugo安装我推荐使用chocolatey包管理器进行安装，接触过Linux的朋友们都知道，Linux的各种包管理器，利用命令行就可以实现包的更新，删除等操作，Windows下也有类似的包管理器就是chocolatey了。\n安装过程详解\n  安装chocolatey包管理器：在官网点击 Install Now 即可下载\n  命令行中敲入choco --version，如果显示版本号证明你的 chocolatey 已经安装完毕，如果有误请检查环境变量\n  命令行中安装hugo：\n1  choco install hugo -confirm   安装hugo-extended（扩展版本）：\n1  choco install hugo-extended -confirm     检查hugo是否安装成功：命令行中敲入hugo version\n  2、初步建站实战（利用GithubPages进行部署）  在Github中建立一个仓库，仓库名为用户名.github.io   将仓库clone到本地一个你想存放网站文件的文件夹  1  git clone \u0026lt;YOUR-REPOSITORY_URL\u0026gt;    创建网站：在存放你博客的根目录 \u0026lt;YOUR-REPOSITORY_URL\u0026gt; 中敲入以下命令  1 2  //注意site后面是一个点，不能忽略啊，.代表当前目录 hugo new site .    添加主题（以我博客的主题Zzo为例子）：  1 2  git init git submodule add https://github.com/zzossig/hugo-theme-zzo.git themes/zzo    把 themes/zzo 下的 exampleSite文件夹的内容复制到你博客的根目录 在博客根目录中敲命令：（启动hugo服务器）  1  hugo server    点击这里查看测试（主题和示例网站中的markdown博客都正确显示了）  3、GithubPages服务 + 云托管 1 - 配置GithubPages服务进行个人博客的部署，使得所有人都可以访问你的博客站  在 config.toml 文件中设置 baseURL 为 Github Pages 服务的域名（用户名.github.io）  1 2 3 4 5  #config/config.toml baseURL = \u0026#34;https://blog.calvinhaynes.top/\u0026#34; #未设置阿里云托管之前应该是 \u0026#34;https://用户名.github.io\u0026#34; title = \u0026#34;Calvin Haynes\u0026#39;s Blog\u0026#34; theme = \u0026#34;zzo\u0026#34;    将更改过后的 github 仓库文件夹（就是你的博客根目录）推送到远端 在Github上设置GithubPages服务的一些参数  （Ps：有关 Custom domain 在以下的云托管中进行解释）\n2 - 云托管（阿里云） ​\t博主买了阿里云的学生机，一个1核2GB内存的轻量应用服务器，所以将博客站云托管在这个服务器上，以下就是基于阿里云的教程，其他服务器也都差不太多，可以自行google，有关阿里云服务器购买和初步配置自行到官网查看文档吧。\n 拥有一个阿里云服务器还不够，你需要购买注册一个你自己的专属域名。 拥有自己的专属域名之后，进入域名解析的工作台，就可以看见你的域名了   解析设置：（点击修改后各种参数的设置都有相关说明，其他问题也都可以在阿里云官网找到文档解释）   服务器绑定域名：   解析设置完后在你的博客根目录中的 static （静态文件存放的地方）中创建一个 CNMAE 文件（注意没有任何后缀）    CNAME 文件中写入你设置的域名，我的就是 blog.calvinhaynes.top ，写完记得更新github库（CNAME文件就是给你这个Github库绑定域名用的，CNAME的全名就是 Canonical Name，意思是别名）\n  最后更改 Github pages 配置中的 Custom domain 为你设置的新域名就好咯\n   现在就可以输入你设置的域名进行访问咯，阿里云服务器在中国，所以访问速度快的一批！！！（别忘了config.toml文件的baseURL参数设置）  2 - 主题参数设置和个性化 ​\t这部分主要是看主题作者写的详细文档进行自己的设计，在Hugo官网中找到的比较热门的主题的Github库中都有相关的文档，建议小伙伴们自行查看学习，每个主题都有不同之处，我使用的是Zzo主题，它的官方文档在这里\n​\t我的Github仓库在这里，欢迎 fork 和查看配置文件\n3 - 资源整理（一些有用的文档） Zzo主题官方文档\n阿里云云解析DNS文档\nhugo文章的front matter\n","description":"利用Hugo静态博客框架创建个人博客站的教程","id":7,"section":"posts","tags":["Hugo","Github"],"title":"Hugo搭建个人博客教程（GithubPages + 阿里云）","uri":"https://blog.calvinhaynes.top/posts/hugo/"},{"content":"我是一个热爱IT技术和音乐的Dream Chaser，正在努力培养计算机的深度和广度认知，也会和各位分享我的Acoustic Music (๑❛ᴗ❛๑)，感谢各位的关注！！\n联系我的话，可以邮箱（chx1006488386@163.com）或者留言哦！！也欢迎大家加入我创建的技术交流群（QQ群号：725133797，下方企鹅图标点击可以直接跳转加群申请界面）\n 同时我在Bilibili上也上传了一些视频，欢迎大家前来观摩。\n .aspect-ratio { position: relative; width: 100%; height: 0; padding-bottom: 75%; } .aspect-ratio iframe { position: absolute; width: 100%; height: 100%; left: 0; top: 0; }    ","description":"博主的个人简介","id":8,"section":"","tags":null,"title":"关于博主","uri":"https://blog.calvinhaynes.top/about/"}]